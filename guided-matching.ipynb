{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_guided_matching(kp1, kp2, des1, des2, H_coarse, radius_in_pixels=10):\n",
    "    # kp1 and kp2 are both lists of cv.KeyPoint objects.\n",
    "\n",
    "    # Normally, we need des1 and des2 to match the keypoints.\n",
    "    # But for guided matching, we have an initial homography estimation which is coarsely true.\n",
    "    # For very coarse homographies, radius_in_pixels should be large.\n",
    "\n",
    "    # Cross check verimlilik icin iyi degil, pek anlamli da degil. Istenirse belki ratio test eklenebilir.\n",
    "\n",
    "    def filter_pts(pts, pt, radius_in_pixels):\n",
    "        # pts is numpy array of shape (N, 2)\n",
    "        # pt is numpy array of shape (2,)\n",
    "        # radius_in_pixels is a scalar.\n",
    "        # Returns a list of indices of pts that are within radius_in_pixels of pt.\n",
    "        idx_list = []\n",
    "        for idx, pt_candidate in enumerate(pts):\n",
    "            if np.linalg.norm(pt_candidate - pt) <= radius_in_pixels:\n",
    "                idx_list.append(idx)\n",
    "        return idx_list\n",
    "\n",
    "\n",
    "    def match_pts(descriptor, des2, pt_idx_list):\n",
    "        # descriptor is numpy array of shape (K,)\n",
    "        # des2 is numpy array of shape (N, K)\n",
    "        # pt_idx_list is a list of indices of des2.\n",
    "        # Returns the index of the best match in pt_idx_list.\n",
    "        distance_closest = np.inf\n",
    "        idx_closest = None\n",
    "        for idx in pt_idx_list:\n",
    "            distance = np.linalg.norm(descriptor - des2[idx])\n",
    "            if distance < distance_closest:\n",
    "                distance_closest = distance\n",
    "                idx_closest = idx\n",
    "\n",
    "        return idx_closest, distance_closest\n",
    "\n",
    "    \n",
    "    pts1 = np.array([kp.pt for kp in kp1])\n",
    "    pts2 = np.array([kp.pt for kp in kp2])\n",
    "\n",
    "    # Transform pts1 to pts1_transformed using H_coarse.\n",
    "    pts1_transformed = cv.perspectiveTransform(pts1.reshape(-1, 1, 2), H_coarse).reshape(-1, 2)\n",
    "\n",
    "    # For each point in pts1_transformed, find the indices of points in pts2 that are within radius_in_pixels pixels.\n",
    "\n",
    "    # TODO: Verimlilik icin burada aslinda quadtree falan kullanilmali.\n",
    "    pt_idx_list_list = []\n",
    "    for pt1_transformed in pts1_transformed:\n",
    "        pt_idx_list = filter_pts(pts2, pt1_transformed, radius_in_pixels)\n",
    "        pt_idx_list_list.append(pt_idx_list)\n",
    "    \n",
    "    matches = []\n",
    "    for idx, pt_idx_list in enumerate(pt_idx_list_list):\n",
    "        if len(pt_idx_list) == 0:\n",
    "            continue\n",
    "\n",
    "        idx_closest, distance_closest = match_pts(des1[idx], des2, pt_idx_list)\n",
    "        assert idx_closest is not None\n",
    "        match = cv.DMatch(idx, idx_closest, distance_closest)\n",
    "        matches.append(match)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "\n",
    "# TODO: AdaLAM'e benzer sekilde angle ve size bilgilerini de kullanabiliriz.\n",
    "# Ama findHomography'de bu bilgi kullanilmiyor. Neden? (2 noktadan homografi bulma makalesinde kullaniliyor!)\n",
    "# Gerci match etme kismi findHomography'dense AdaLAM'e daha cok benziyor. Ama orada bule opsiyoneldi sanki bu kullanim.\n",
    "\n",
    "# TODO: Daha da onemlisi su: Homografinin her yerinde ayni miktarda hata beklenmez.\n",
    "# Homografinin genisletme yaptigi yerlerde daha cok hata beklenir.\n",
    "# Dolayisiyla sabit bir radius_in_pixels olmaz.\n",
    "# Bizim ilk imgede o noktadaki bir radius_in_pixels yaricapli cemberimiz karsida gittigi yerde ne kadar boyutta oluyorsa o kadarlik bir alanda arama yapmak lazim.\n",
    "# Tabii aslinda cember cembere gitmiyor, elips falan oluyor ama boyle aramasi daha kolay. (Belki oyle dusunmek lazim?)\n",
    "# Bu olayin keypointlerin sizelariyla bir alakasi yok! Onunla karistirma. \n",
    "# Beklenen hata miktarinin imgenin her yerinde farkli olmasiyla alakasi var.\n",
    "\n",
    "# Kabaca dogru homografiler vererek bunu test edebiliriz.\n",
    "# Kabaca dogru homografileri nasil bulacagiz?\n",
    "# Mesela imgenin kose noktalarini gercek homografiyle tasiriz. Sonra bunu biraz bozarak homografiyi hesaplariz (4 eslesmeden). \n",
    "# Ama gercekte boyle olmaz ki!? Daraldigi yerlerde az, genisledigi yerlerde daha cok hata olmaz mi?\n",
    "# Ustte de o durumdan bahsetmistim zaten.\n",
    "# Su olmaz mi acaba?\n",
    "# Normal algoritma calistirilir. Bulunan inlierlardan rastgele 4 tanesinden homografi hesaplanir. Kabaca dogru olmali sonuc.\n",
    "# Eger ki findHomography'deki threshold yuksekse daha coarse bir homografi elde edilir.\n",
    "# Gerci simdi dusunuyorum da reprojection error (symmetric?) homografinin her yerine esit muamele yapmiyor mu? \n",
    "# Adaptive degil ki. Bu da ayri bir fikir. Neden adaptive olmasin? Ama yapmak mantikli olsaydi muhtemelen simdiye kadar yapilirdi.\n",
    "\n",
    "# Kaba homografileri nasıl bulacağımı buldum gibi. İmgeleri küçültüp algoritmaları çalıştır. Sonra imgeleri geri büyüt. \n",
    "# Bu gerçekçi olur. Ne kadar küçültürsen o kadar kaba homografi olur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emre'ye coarse homography'den fine homography bulma challenge yaptirilabilir.\n",
    "# Know-how olusturmasi lazim. Feature extractordan vb. bagimsiz veya onlar ozelinde.\n",
    "# Deneyler tasarlamak ve calistirmak, hipotezler test etmek lazim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.523\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "\n",
    "def estimate_coarse_homography(img1_path, img2_path, img_divider=4, pts_divider=2.5):\n",
    "    # Normalde boyle bir fonksiyon olmaz. Kabaca dogru sonuc bulmayi simule ediyoruz.\n",
    "    # Hem img kucultulecek hem de bulunan inlier matchlerin sadece bir kismi kullanilacak.\n",
    "\n",
    "    img1 = cv.resize(read_image(img1_path, is_grayscale=True), (0, 0), fx=1/img_divider, fy=1/img_divider)\n",
    "    img2 = cv.resize(read_image(img2_path, is_grayscale=True), (0, 0), fx=1/img_divider, fy=1/img_divider)\n",
    "\n",
    "    kp1 = detect_keypoints(img1)\n",
    "    kp2 = detect_keypoints(img2)\n",
    "\n",
    "    des1 = compute_descriptors(img1, kp1)\n",
    "    des2 = compute_descriptors(img2, kp2)\n",
    "\n",
    "    kp1 = [cv.KeyPoint(kp.pt[0] * img_divider, kp.pt[1] * img_divider, kp.size, kp.angle, kp.response, kp.octave, kp.class_id) for kp in kp1]\n",
    "    kp2 = [cv.KeyPoint(kp.pt[0] * img_divider, kp.pt[1] * img_divider, kp.size, kp.angle, kp.response, kp.octave, kp.class_id) for kp in kp2]\n",
    "\n",
    "    bf = cv.BFMatcher(cv.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "\n",
    "    pts1 = np.int32([kp1[m.queryIdx].pt for m in matches])\n",
    "    pts2 = np.int32([kp2[m.trainIdx].pt for m in matches])\n",
    "\n",
    "    _, mask = cv.findHomography(pts1, pts2, method=cv.RANSAC, ransacReprojThreshold=3.0)\n",
    "\n",
    "    masked_pts1 = pts1[mask.ravel() == 1]\n",
    "    masked_pts2 = pts2[mask.ravel() == 1]\n",
    "\n",
    "    masked_pts1 = masked_pts1[:int(len(masked_pts1) / pts_divider)]\n",
    "    masked_pts2 = masked_pts2[:int(len(masked_pts2) / pts_divider)]\n",
    "\n",
    "    H_estimated, _ = cv.findHomography(masked_pts1, masked_pts2, method=0, ransacReprojThreshold=3.0)\n",
    "\n",
    "    return H_estimated, img1, img2\n",
    "\n",
    "\n",
    "img1_no = 1\n",
    "img2_no = 3\n",
    "\n",
    "img_divider = 4\n",
    "pts_divider = 2.5\n",
    "\n",
    "img1_path = f'homography_dataset/img{img1_no}.png'\n",
    "img2_path = f'homography_dataset/img{img2_no}.png'\n",
    "h_path = f'homography_dataset/H{img1_no}to{img2_no}p'\n",
    "\n",
    "H_estimated, img1, img2 = estimate_coarse_homography(img1_path, img2_path, img_divider, pts_divider)\n",
    "\n",
    "if img1_no == img2_no:\n",
    "    H_true = np.eye(3)\n",
    "else:\n",
    "    H_true = np.loadtxt(h_path)\n",
    "\n",
    "print(round(average_corner_error(img1.shape[0] * img_divider, img1.shape[1] * img_divider, H_true, H_estimated), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_ori = read_image(img1_path, is_grayscale=True)\n",
    "img2_ori = read_image(img2_path, is_grayscale=True)\n",
    "\n",
    "kp1_ori = detect_keypoints(img1_ori)\n",
    "kp2_ori = detect_keypoints(img2_ori)\n",
    "\n",
    "des1_ori = compute_descriptors(img1_ori, kp1_ori)\n",
    "des2_ori = compute_descriptors(img2_ori, kp2_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = perform_guided_matching(kp1_ori, kp2_ori, des1_ori, des2_ori, H_estimated, radius_in_pixels=10)\n",
    "\n",
    "# img2_no=4, img_divider=4, pts_divider=2.5\n",
    "# ACE 15.142\n",
    "\n",
    "# Bu algoritmada radius_in_pixels degerinin az ya da fazla olmasi sureyi etkilemiyor.\n",
    "# Verilen ornekte 3-4 dk suruyor.\n",
    "\n",
    "# radius_in_pixels=5  -> ACE 11.839\n",
    "# radius_in_pixels=10 -> ACE 1.787\n",
    "# radius_in_pixels=20 -> ACE 6.511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.596\n"
     ]
    }
   ],
   "source": [
    "pts1 = np.int32([kp1_ori[m.queryIdx].pt for m in matches])\n",
    "pts2 = np.int32([kp2_ori[m.trainIdx].pt for m in matches])\n",
    "\n",
    "H_final, _ = cv.findHomography(pts1, pts2, method=cv.RANSAC, ransacReprojThreshold=3.0)\n",
    "print(round(average_corner_error(img1_ori.shape[0], img1_ori.shape[1], H_true, H_final), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Make perform_guided_matching faster. For example, use a quadtree to find the nearest neighbor of each point. \"timeit\" the implementations.\n",
    "# Süreyi etkileyen değişkenlerin farklı değerleri için sürenin grafiğini çiz ve yorumla. (x ekseni değişken değeri, y ekseni süre gibi, her iki implementasyon da çizilir aynı şekil üzerinde.)\n",
    "\n",
    "# Task 2: Try to improve perform_guided_matching. For example, use an adaptive radius with respect to H_coarse.\n",
    "# Performansı (başarıyı) etkileyen değişkenlerin farklı değerleri için performans (veya hata) grafiğini çiz ve yorumla.\n",
    "\n",
    "# Task 3: Try to improve perform_guided_matching by making it free of the parameter \"radius_in_pixels\".\n",
    "# Task 2'deki gibi grafik çiz."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
